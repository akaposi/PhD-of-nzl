\chapter{Type Theory}
\label{bg}

A type theory usually refers to a formal system in which every term always has a type. It was initially invented as a foundation of \maths as an alternative to set theory, but it also works well in computer science as a programming languages  in which we can write certified programs. There are a variety of type theories, like Russell's theory of types, simply typed $\lambda$-calculus, Gödel's System T \cite{gdl:1931} etc. In this thesis we mainly focus on Per Martin-L\"{o}f's intuitionistic type theory. There are also different versions of \mltt and the intensional version (\itt for short) has better computational behaviour and widely used in programming languages like Agda, Epigram etc. However several desirable extensional concepts such as functional extensionality and quotient types are not available in \itt. Much research has been done to extend Type Theory with these concepts and new interpretations of type theory are popular and reasonable solutions. \hott is one of them and is also a variant of \mltt and connected to homotopy theory. 


In this chapter we will first briefly introduce the original motivation and evolution of type theory. Then we explain important notions in \mltt, and a list of extensional concepts will be presented. Finally we will also introduce the main programming language Agda which is an implementation of the intensional version of \mltt.


\section{A brief history of Type Theory}

Type theory was first introduced as a refinement of set theory. 
In the 1870s, George Cantor and Richard Dedekind founded set theory as a branch of mathematical logic and started to use set theory as a language to describe definitions of various mathematical objects.
In the 1900s, Bertrand Russell discovered a paradox in this system. In the naïve set theory, there was no distinction between small sets like the set of natural numbers and "larger" sets like the set of all sets.

\begin{example}[Russell's Paradox]
Let $R$ be the set of all sets which do not contain themselves
$R = \{x ~| ~x \not\in  x\}$
Then we get a contradiction
$R \in R \iff R \not\in R$
\end{example}

To avoid this paradox, Russell and Frege found that they have to make a distinction between objects, predicates, predicates of predicates, etc. Then Russell proposed the theory of types \cite{rus:1903} where the distinction is internalised by types.
In this simple type theory, each mathematical object is assigned a type. This is done in a hierarchical structure such that "larger" sets and small sets reside in different levels. The "set" of all
sets is no longer a small set, hence the
paradox disappears.

In type theory, The elementary notion \emph{type} plays a similar role to set in set theory, but differs fundamentally. Every term comes with its unique type while in set theory, an element can belong to multiple sets.
For example to state a term of natural number $2$, we have to use a typing judgement $2:\N$, where $\N$ is the set of natural numbers. The term are usually constructed using a list of constructors binding to its type. Hence a term of integer $2 : \Z$ is different to $2:\N$ in type theory, while it is not the case in set theory.

Following the idea of theories of types, various type theories have been developed since then. 
Simply typed lambda calculus (or Church's theory of types) is the first type theory to introduce functions as primitive objects \cite{sep-type-theory}. It was originally introduced by Alonzo Church in 1940 to avoid the Kleene-Rosser paradox \cite{kleene1935inconsistency} in his untyped lambda calculus.

\begin{example}[Kleene-Rosser paradox]
Suppose we have a function $f = \lambda x . \neg (x ~ x) $, then we can deduce a contradiction by applying it to itself:

$f f = (\lambda x . \neg (x ~ x)) f = \neg (f ~ f)$
\end{example}

It is applied to various fields including computer science. For instance, Haskell was originally based on one of the variants of lambda calculus called System F\footnote{It has evolved into System FC recently}. 


%There are also other refinements of lambda calculus which is illustrated by the $\lambda$-cube \cite{barendregt1991introduction}.

In 1970s, Per Martin-L\"{o}f \cite{per:71,per:82} developed his profound intuitionistic type theory (also called \mltt). In this thesis, we will use \emph{Type Theory} specially for it if unambiguous.
It serves as a foundation of constructive mathematics \cite{martin1984intuitionistic} and also can be used as a functional programming language \cite{DBLP:dblp_journals/tcs/Troelstra99} in
which the evaluation of a well-typed program always terminates \cite{nor:90}. 


From early type theories like Russell's and Church's to modern type theories like de Bruijn's Automath, \mltt and Coquand's Calculus of Constructions (CoC), one of the most important extension and discovery is the correspondence between mathematical proofs and computer programs (terms).
Different to set theory whose axioms are based on first-order logic, in modern type theories, intuitionistic logic concepts can be encoded as types through the 
\textbf{Curry-Howard isomorphism (correspondence)}.
The American mathematician Haskell Curry and logician William Alvin Howard first discovered a correspondence between logic and computation. They found that mathematical proofs or generally propositions can be encoded as types and proofs can be given by constructing terms (programs). The idea also relates to the Brouwer–Heyting–Kolmogorov (BHK) interpretation of intuitionistic logic. For example, a proof of $P \wedge Q$ can be encoded as a product type $P \times Q$ which contains a proof of $p : P$ and a proof of $q : Q$. Computationally, implications are function types, conjunctions are product types, true is unit type, false is empty type etc. 
With dependent types (See \ref{dpty} below), the correspondence extends to predicate logic: the universal and existential quantification correspond to dependent functions and dependent sums. 
This feature turns Type Theory into a programming language where we can formalise proofs as computer programs. We can do computer-aided reasoning about mathematics as well as programs. From a programmer's perspective, it provides a programming language where we can write certified programs.

% also cite http://www.cs.ru.nl/~herman/onderwijs/provingwithCA/paper-lncs.pdf}
% cite http://plato.stanford.edu/entries/type-theory/

Another central concept in \mltt is \textbf{Dependent types}\label{dpty}.
A dependent type is a type which depends on values of other types \cite{dtw}. It provides us the means for defining families of types, for example, a family of lists with explicit length called \emph{Vector}, for example $\text{Vec} ~\N ~3$ stands for a three element list of $\N$. Since there is more information in the type, the program specifications can be expressed more accurately. In the example of vectors, we can write a look-up function without "index out of range" problems. It is much simpler to write multiplication of matrix with dependent types.


The 1971 version  of \mltt \cite{per:71} was impredicative and turned our to be inconsistent due to Girard's paradox \cite{hurkens1995simplification}. It is impredicative in the sense that the universe of types is impredicative. The notion of a \textbf{universe of types} was first used by Martin-L\"{o}f \cite{Martin-Lof-1973} to describe the type of all types and usually denoted as $\mathsf{U}$. An impredicative universe $\mathsf{U}$ has an axiom $\mathsf{U} : \mathsf{U}$.
Starting from the 1972 version \cite{Martin-Lof-1972}, a predicative hierarchy of universes is adopted and they are more widely used. Briefly speaking, it starts from a universe of small types called $U_0$ and for each $n : \N$ we have $U_n : U_{n+1}$ which forms a cumulative hierarchy of universe. There is a more detailed introduction to the notion of universe written by Erik Palmgren \cite{Palmgren98onuniverses}.


\textbf{Equality} is always one of the most contentious topics in Type Theory.
In regular mathematics the notion of equality is usually used to describe sameness and taken as a given.
But in Type Theory, we have different notions of equality or equivalence of the terms.
First of all, \textbf{definitional equality} is a judgement-level equality, e.g.\  $a \equiv b$, which holds when two terms have the same normal forms \cite{nor:90}. It is also called \textbf{judgemental equality} \cite{martin1984intuitionistic}. Usually it already includes \textbf{computational equality} which is the congruence on terms generated from reduction rules like $\beta$-reduction and $\eta$-expansion. 


Since equalities are also propositions, they can be encoded as types.
In the 1972 version of \mltt, there is a type for the equality of natural numbers. It is defined by pattern matching on the two numbers and eventually reduces to unit type or empty type.

In the 1973 version \cite{Martin-Lof-1973}, Martin L\"{o}f introduced an equality type which works for every type, not only for natural numbers. It is called \textbf{identity type} or \textbf{intensional propositional equality} or \textbf{intensional equality}. It is denoted e.g.\ for natural numbers by $\text{Id}_{\N}(a, b)$ or $a =_{\N} b$ (See its definition in \ref{idtypes}).


In \itt (TT$_I$ for short), like the 1973 version or Agda, propositional equality is different from definitional equality. 
The definitional equality is always decidable hence type checking that depends on definitional equality is
decidable as well~\cite{alti:lics99}.



In \ett (TT$_E$ for short), like the 1980 version \cite{martin1984intuitionistic} or NuPRL, propositional equality is undistinguished from definitional equality, in other words, two propositional equal objects are judgementally equal. This is achieved by the \textbf{equality reflection rule}:

\begin{equation}
\label{reflection}
\infer[\text{ID-DEFEQ}]{a \equiv b}{a = b}
\end{equation}

and the \textbf{uniqueness of identity proofs}:

\begin{equation}
\label{ID-Uni}
\infer[\text{ID-UNI}]{p \equiv \text{refl}}{p : a = b}
\end{equation}

Notice that this version of UIP type checks only if we have \ref{reflection}. In some versions of \itt, UIP also holds in other forms, see \autoref{UIPdetail}. 

Due to the addition of \ref{reflection}, the type checking becomes undecidable because it has to respect propositional equality which is not decidable in general. For example, the equality reflection rule implies functional extensionality which is not decidable.

\itt is more widely used by programming languages such as Coq, Agda and Epigram, because its type checking is decidable and terminating.

However in \itt, \textbf{extensional equality} is not available. For example equality of functions, equality of different proofs for the same proposition, and more extensional concepts like quotient types are desirable and reasonable to acquire. However simply axiomatising them can result in non-canonical objects e.g.\ a term of $\N$ which are not reducible to numerals (see \autoref{noncanonical}). 


To add these extensional concepts into \itt without losing decidable type checking and canonicity, it seems that types have to be interpreted with more complicated structures than sets.
In 1990s, there are some models of Type Theory proposed such as Hofmann's setoid model, Altenkirch's setoid model, Hofmann and Streicher's groupoid model etc.
The idea of viewing types as groupoids later inspired other mathematicians. For example, Warren \cite{Warren} interprets types as strict \og.

In recent years, Voevodsky proposes a new interpretation of intensional \mltt by homotopy-theoretical notions \cite{klv:ssetmodel,voe:06} called \hott (see \autoref{hott}). It is a univalent foundation of mathematics. 
Type are treated as \emph{spaces} or \emph{higher groupoids}, and terms are \emph{points} of this space, and more generally, functions between types are \emph{continuous maps}. Identity types are \emph{paths}, identity types of identity types are \emph{homotopies}. Although these notions are originally defined with topological bases, we only treat them purely homotopically. The equality is internalised into types such that the types have infinite level of higher structures as \wog.


%It is one of the most important topics in Type Theory.

%Altenkirch and McBride also introduced a variant of \ett called
%\emph{Observational Type Theory}  \cite{alt:06} in which definitional equality is
%decidable and propositional equality is extensional.

%cite http://adam.chlipala.net/cpdt/html/Equality.html


The new interpretation clarifies the nature of equality in Type Theory.
The central idea of \hott is \text{univalence} which can be understood as the property that isomorphic types are equal.
In regular \maths we usually do abstract reasoning on structures which applies to all isomorphic structures, because they can not be distinguished by other objects, hence isomorphic structures can be identified. Univalence can be seen as a formal acceptance of this idea in Type Theory such that we can do abstract reasoning about types. Moreover many extensional concepts arise from it automatically. The interpretation also helps mathematicians to reason about homotopy theory in programming languages.


To summarise, we present a list of different versions of \mltt:

\begin{enumerate}

\item The 1971 version \cite{per:71} is impredicative and turned our to be inconsistent due to Girard's paradox.

\item The 1972 version which is published in 1996 \cite{Martin-Lof-1972} abandons the impredicative universe and all later versions are predicative. It does not have an inductive identity type but recursively defines equality for given types e.g.\ $\N$.

\item The 1973 version \cite{Martin-Lof-1973} introduced inductively defined identity type to internalising equality as a type. 

\item The 1980 version which is summarised by Giovanni Sambin in 1984 \cite{martin1984intuitionistic} is extensional. It adopts equality reflection, namely an inhabitant of an identity type implies definitionally equality.

\item In the homotopic version \cite{hott}, Vladimir Voevodsky extends it with univalence axiom and provides a homotopic interpretation of it.

\end{enumerate}



\section{The formal system of Type Theory}

The formal type system of Type Theory is given by a list of judgements and a sequence of rules written as derivation of these judgements. Usually we have following judgements in this thesis:


\begin{tabular}{l l}
$\Gamma \vdash$ & $\Gamma$  is a well formed context \\
$\Gamma \vdash A$ & $A$  is a well formed type \\
$\Gamma \vdash a : A$ & $a$ is a well typed term of type $A$ in context $\Gamma$ \\
$\delta : \Gamma \Rightarrow \Delta$ & $\delta$ is a substitution from context $\Gamma$ to $\Delta$ \\
\end{tabular}

There are also equality judgements for contexts, types, terms and substitution. For instance,

$\Gamma \vdash a \equiv a' : A$  ~ $a$ and $a'$ are definitionally equal terms of type $A$ in context $\Gamma$

In \itt the judgemental equality $\equiv$ is the same as definitional equality, while propositional equality is usually expressed by an inhabitant of the identity type $\Gamma \vdash p: a =_{A} a' $.


Throughout the thesis, we usually use the following notational conventions:

\begin{itemize}
\item $\Gamma, \Delta$ for contexts

\item $\gamma, \sigma$ for substitutions

\item $A, B, C$ for types

\item $a, b, c, t, x$ for terms

\item $\defeq$ for definitions

\item $\Set$ or $\Set_0$ for universe of small types, $\Set_1$, $\Set_2$ ... for higher universes

\end{itemize}

\subsection{Rules for types}\label{typerule}


The rules usually describe how we can define types with judgements above. They are syntactic rules but the semantic meaning may be revealed from the construction.
Rules for types are usually classified as formation rule, introduction rule, elimination rule, computation rule ($\beta$) and uniqueness rule ($\eta$). Here we will only show the rules for the most important types. The substitution rules are not discussed here but a good reference is \cite{hof:phd}).


First of all, a \textbf{context} is either empty (denoted as $()$) or extended by context comprehension:

\infrule[comprehension]{\Gamma \vdash \andalso \Gamma \vdash A}{\Gamma,A \vdash }

In practice, the empty context is usually not written, for example $\vdash \N$.

\textbf{$\Pi$-types} (dependent function type)

\begin{multicols}{2}
\infrule[$\Pi$-form]{\Gamma \vdash A \andalso \Gamma , A \vdash B}{\Gamma \vdash \Pi ~(x:A) ~B }
\columnbreak
\infrule[$\Pi$-intro]{\Gamma , x : A \vdash b : B}{\Gamma \vdash \lambda (x:A). b : \Pi ~(x:A) ~B }
\end{multicols}

\infrule[$\Pi$-elim]{\Gamma \vdash f : \Pi ~ (x:A)~B \andalso \Gamma \vdash a : A}{\Gamma \vdash f(a): B[a/x]}

In the expressions like $\lambda (x:A).b$, $\lambda$ binds the free occurrences of $x$ in $b$.
In the expressions like $B[a/x]$ or $b[a/x]$ we do an \emph{standard substitution} in type $B$ or term $b$ that replaces free occurences of $x$ by $a$. We will use a shorthand notation for substitution later, for example, $C[a,b]$ for $C[a/x,b/y]$ where the order of arguments corresponds to the order in the typing rule.

In this thesis, we also adopt a generalised arrow notation to write $\Pi$-types, for example $(x : A) \to B$, and their terms $\lambda (x: A) \to b$.

\begin{multicols}{2}
computation rule
$$(\lambda (x:A) \to b)(a) \equiv b[a]$$

\columnbreak

uniqueness rule
$$f \equiv \lambda x \to f(x) $$
\end{multicols}

\textbf{$\Sigma$-types} (dependent product type)


\begin{multicols}{2}
\infrule[$\Sigma$-form]{\Gamma \vdash A \andalso \Gamma , A \vdash B}{\Gamma \vdash \Sigma ~A ~B }
\columnbreak
\infrule[$\Sigma$-intro]{\Gamma \vdash a : A \andalso \Gamma \vdash b : B[a]}{\Gamma \vdash (a,b) : \Sigma ~A ~B}
\end{multicols}

There are two ways to eliminate a term of $\Sigma$-types,

\begin{multicols}{2}
\infrule[$\Sigma$-proj$_1$]{\Gamma \vdash t : \Sigma ~ A ~B}{\pi_1~t : A}
\columnbreak
\infrule[$\Sigma$-proj$_2$]{\Gamma \vdash t : \Sigma ~ A ~B}{\pi_2~t : B[\pi_1~t]}
\end{multicols}

The computation rule is, $\pi_1 ~(a,b) \equiv a$ and $\pi_2 ~(a,b) \equiv b$

And the uniqueness rule is,

$$t \equiv (\pi_1 ~t, \pi_2 ~t)$$

\textbf{Identity type}\label{idtypes} 

Identity types is a notion of intensional propositional equality given by the following rules:

\begin{multicols}{2}
\infrule[=-form]{\Gamma \vdash A \andalso \Gamma \vdash a : A, \andalso \Gamma \vdash a' : A}{\Gamma \vdash a =_A a'}
\columnbreak
\infrule[=-intro]{\Gamma \vdash a : A}{\Gamma \vdash r(a) : a =_A a}
\end{multicols}

We use  $a =_{A} a'$ instead of $\text{Id}_A(a, a')$ to denote the identity types, or simply $a = a'$.

\infrule[$\J$]{\Gamma , x : A, y : A, p : x =_A y \vdash C  \andalso \Gamma , x : A \vdash t(a) : C[x,x,r(x)] \\ \andalso \Gamma \vdash a: A \andalso \Gamma \vdash a': A \andalso \Gamma \vdash p : a =_A a'}{\Gamma \vdash \J (t,a,a',p): C[a',a',p]}

Its computation rule is,

$$\J (t,a,a,r(a)) \equiv t(a)$$

The \emph{uniqueness of identity proofs} (UIP) is not a consequence of $\J$ but another eliminator called $\K$ (see \autoref{UIPdetail}).


\textbf{Unit type}


\begin{multicols}{2}
\infrule[$\top$-form]{}{\vdash \top}
\columnbreak
\infrule[$\top$-intro]{}{\vdash \textsf{tt} : \top}
\end{multicols}

\infrule[$\top$-elim]{\Gamma ,x : \top \vdash A \andalso \Gamma \vdash t : A[*] }{ \vdash t : A}


\textbf{Empty type}


\begin{multicols}{2}
\infrule[$\bot$-form]{}{\vdash \bot}

\columnbreak

\infrule[$\bot$-elim]{\Gamma \vdash A \andalso e: \bot}{\Gamma \vdash \text{abort}(e) : A}

\end{multicols}

There is no term of the empty type so there is no introduction rule.

\textbf{Universe types}


\begin{multicols}{2}

\infrule[$\mathsf{U}$-form]{}{\Gamma \vdash \mathsf{U}}


\columnbreak

\infrule[$\mathsf{U}$-El]{\Gamma \vdash \hat{A} : \mathsf{U}}{\Gamma \vdash \mathsf{El}({\hat{A}})}

\end{multicols}

The notation of $\hat{A}$ indicates that it is a code for a type (a term of $\mathsf{U}$) rather than a type.


\textbf{Inductive types}\label{df:inductivetypes}

Inductive types is a self-referential schema to define new types by specifying a collection of \emph{constructors} which can be constants and functions.

The formation and introduction rules of a type is enough to build a type inductively. Examples like
natural numbers $\N : \Set$ can be defined as follows:

\begin{itemize}
\item $0 : \N$
\item $\text{suc} : \N \rightarrow \N$
\end{itemize}

The terms are freely generated by a finite list of these constructors, for instance, $\text{suc} ~(\text{suc} ~0)$ stands for natural number $2$. They are similar to data structures in programming languages, so most systems of Type Theory used as programming languages have inductive types along with structural recursion to eliminate or use them.


\section{An implementation of Type Theory : Agda}

Agda is a dependently typed functional programming language which is based on the intensional version
of \mltt \cite{agdawiki:main}. 

\begin{itemize}

\item \textit{Functional programming language}. As the name indicates that, functional programming languages emphasise the application of functions rather than changing data in the imperative style like C{}\verb!++! and Java. The basis of functional programming is the lambda calculus. There are several generations of functional programming languages, for example Lisp, Erlang, Haskell, SML etc. 
Agda is a pure functional programming language which offers lazy evaluation (see \ref{lazyeval}) like Haskell. In a pure language, side effects are eliminated which means we ensure that the result will be the same no matter how many times we input the same data. 
%Most of the applications of them are currently in the academic fields, however as the functional programming developed, more applications will be explored.

\item \textit{Implementing Per Martin-L\"{o}f Type Theory}. It is a variant of \itt which is based on the Curry-Howard isomorphisms \cite{aboa}. It means that we can reason about \maths and programs by constructing proofs as programs. In many languages the correctness of programs has to be verified on the meta-level. However in Agda we verify programs within the same language, and express specifications and  programs at the same time as Nordström et al. \cite{nor:90} pointed out.


\item \textit{Dependent types}. 
As a feature of Martin-L\"{o}f intuitionistic Type Theory (see \ref{dpty}), types in Agda can depend on values of other types \cite{dtw}, which is different from Haskell and other Hindley-Milner style languages where types and values are clearly distinct. It not only helps us encode quantifiers but also allows writing very expressive types as program specifications such that programs become are less error-prone.
For example, in Agda the type of matrices comes with accurate size e.g.\ $\text{Matrix}~3~4$. Thus we can specify the multiplication of matrices as a function of type $\text{Matrix}~m~n \to \text{Matrix}~n~p \to \text{Matrix}~m~p$ where $m,n,p : \N$. 
\end{itemize}


\subsection{Features}\label{features}

Some features of being a functional programming language makes theorem proving easier,

\begin{itemize}
\item \textit{Pattern matching}. The mechanism for dependently typed pattern matching is very powerful \cite{alti:pisigma-new}. Pattern matching is a more intuitive way to use terms than eliminators. For example, by pattern matching on a term of identity type, the two sides on the equation automatically becomes the same in the context so that we can simply prove the symmetry of identity as,

\begin{code}
\\
\>\AgdaFunction{symm} \AgdaSymbol{:} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}\{}\AgdaBound{a} \AgdaBound{b} \AgdaSymbol{:} \AgdaBound{A}\AgdaSymbol{\}} \AgdaSymbol{→} \AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{b} \AgdaSymbol{→} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{a}\<%
\\
\>\AgdaFunction{symm} \AgdaInductiveConstructor{refl} \AgdaSymbol{=} \AgdaInductiveConstructor{refl}\<%
\\
\end{code}

compared to the case of using the eliminator $\J$.

\begin{code}\label{symmetry}
\\
\>\AgdaFunction{symm'} \AgdaSymbol{:} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}\{}\AgdaBound{a} \AgdaBound{b} \AgdaSymbol{:} \AgdaBound{A}\AgdaSymbol{\}} \AgdaSymbol{→} \AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{b} \AgdaSymbol{→} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{a}\<%
\\
\>\AgdaFunction{symm'} \AgdaSymbol{=} \AgdaFunction{J} \AgdaSymbol{(λ} \AgdaBound{a} \AgdaBound{b} \AgdaBound{\_} \AgdaSymbol{→} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{a}\AgdaSymbol{)} \AgdaSymbol{(λ} \AgdaBound{\_} \AgdaSymbol{→} \AgdaInductiveConstructor{refl}\AgdaSymbol{)} \AgdaSymbol{\_} \AgdaSymbol{\_}\<%
\\
\end{code}

\item \textit{Inductive \& Recursive definition}. In Agda, types are often defined inductively, for example, natural numbers are defined as:

\begin{code}\>\<%
\>\AgdaKeyword{data} \AgdaDatatype{ℕ} \AgdaSymbol{:} \AgdaPrimitiveType{Set} \AgdaKeyword{where}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{zero} \AgdaSymbol{:} \AgdaDatatype{ℕ}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{suc} \<[7]%
\>[7]\AgdaSymbol{:} \AgdaSymbol{(}\AgdaBound{n} \AgdaSymbol{:} \AgdaDatatype{ℕ}\AgdaSymbol{)} \AgdaSymbol{→} \AgdaDatatype{ℕ}\<%
\>\<\end{code}

Function on inductive types are usually recursively defined using pattern matching. For example the addition of natural numbers are usually defined as:

\begin{code}\>\<%
\\
\>\AgdaFunction{\_+\_} \AgdaSymbol{:} \AgdaDatatype{ℕ} \AgdaSymbol{→} \AgdaDatatype{ℕ} \AgdaSymbol{→} \AgdaDatatype{ℕ}\<%
\\
\>\AgdaInductiveConstructor{zero} \<[6]%
\>[6]\AgdaFunction{+} \AgdaBound{n} \AgdaSymbol{=} \AgdaBound{n}\<%
\\
\>\AgdaInductiveConstructor{suc} \AgdaBound{m} \AgdaFunction{+} \AgdaBound{n} \AgdaSymbol{=} \AgdaInductiveConstructor{suc} \AgdaSymbol{(}\AgdaBound{m} \AgdaFunction{+} \AgdaBound{n}\AgdaSymbol{)}\<%
\>\<\end{code}

It also enables programmers to prove propositions in the same manner as mathematical induction and case analysis.

\item \textit{Lazy evaluation}\label{lazyeval}. As a pure functional programming language, it offers lazy evaluation which eliminates unnecessary operation to delay a computation until we need its result. It is often used to handle infinite data structures \cite{wiki:Lazy_evaluation}.

\end{itemize}

Compared to other programming languages like Haskell, there is an interactive Emacs interface which provides a few important functions.

\begin{itemize}
\item \textit{Type checker}. Type checker is an essential part of Agda. It will detect type mismatch problems when some codes are loaded into Agda.
It also includes a coverage checker and a termination checker.
The \emph{coverage checker} ensures that the patterns cover all possible cases so that programs do not crash \cite{aboa}. 
The \emph{termination checker} ensures functions must terminate in Agda \cite{tutorial}.  As a theorem prover, the type checker hence ensures that the proof is complete and not defined by itself. 

 
\item \textit{Interactive interface}. It has an Emacs-based interface for interactively writing and verifying proofs.
As long as code is loaded, namely type checked, the code will be highlighted and problematic code is coloured by red for non-terminating and yellow for not inferable. 
In the interactive Emacs, there are a few convenient short-cut keys, for example showing the context, refining the goal with a partial program, navigating to definitions of some functions or types. The refinement function helps us incrementally build programs with explicit context information. Thus type signatures are usually essential for accurate information.
The code navigation alleviates a great deal of work of programmers to look up the documentations.


\item \textit{Unicode and mixfix support}. In Haskell and Coq, unicode support is not an essential part. The name of operations can be very complicated without enough symbols. However in Agda, it provides unicode inputs and reads unicode symbols like $\beta$, $\forall$ and $\exists$. 

It also uses a flexible mixfix notation where the positions of arguments are indicated by underscores.
E.g.\ $\_⇒\_$ is one identifier which can be applied to two arguments as
in $A ⇒ B$.

In the following type signature of the commutativity theorem for addition of natural numbers, $\AgdaDatatype{ℕ}$ and $\AgdaDatatype{≡}$ are unicode characters, $\AgdaFunction{+}$ and $\AgdaDatatype{≡}$ are mixfix operators. 

\begin{code}%
\>\AgdaFunction{comm} \AgdaSymbol{:} \AgdaSymbol{∀} \AgdaSymbol{(}\AgdaBound{a} \AgdaBound{b} \AgdaSymbol{:} \AgdaDatatype{ℕ}\AgdaSymbol{)} \AgdaSymbol{→} \AgdaBound{a} \AgdaFunction{+} \AgdaBound{b} \AgdaDatatype{≡} \AgdaBound{b} \AgdaFunction{+} \AgdaBound{a}\<%
\end{code}

Note that in Agda $\AgdaDatatype{≡}$ is used for identity types. See discussion in \autoref{agdaconventions}.


%Note that $\AgdaFunction{+}$ is not primitive operator in Agda, and identity types are denoted as $\AgdaBound{a} \AgdaDatatype{≡} \AgdaBound{b}$ because $=$ is reserved for function definitions. 

The unicode symbols and mixfix notations improves the readability and provides familiar symbols used in \maths.
Interestingly we could use some characters of other languages to define functions such as Chinese characters.

\item \textit{Implicit arguments and wildcards}. Sometimes it is unnecessary to state an argument. If an argument can be inferred from other arguments we can mark it as implicit with curly brackets. For example, whenever we feed an argument $a$ to function $\AgdaFunction{id}$,  the implicit type $A$ is inferable,

\begin{code}\>\<%
\\
\>\AgdaFunction{id} \AgdaSymbol{:} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}} \AgdaSymbol{→} \AgdaBound{A} \AgdaSymbol{→} \AgdaBound{A}\<%
\\
\>\AgdaFunction{id} \AgdaBound{a} \AgdaSymbol{=} \AgdaBound{a}\<%
\>\<\end{code}

If an explicit argument can be automatically inferred or not used in the program definition, we can replace it with underscores as wildcards (see the code on $\AgdaFunction{symm'}$ above in \autoref{symmetry}).

In practice, the use of implicit arguments and wildcards makes the code more readable.


\item \textit{Module system}. The mechanism of parametrised modules makes it possible to define generic operations and prove a whole set of generic properties.


\item \textit{Coinduction}. We can define coinductive types such as streams in Agda which are typically infinite data structures. Coinductive occurrences must be labelled with $\infty$ and coinductive types do not need to terminate but have to be productive. It is often used in conjunction with lazy evaluation. \cite{wiki:Coinduction}

For coinductive types and more generally mixed inductive/coinductive types \cite{txa:mpc2010g}, we adopt a set of operators which are defined in module \textbf{Coinduction}. Infinite lists (or streams) can be defined as:

\begin{code}
\>\AgdaKeyword{data} \AgdaDatatype{Stream} \AgdaSymbol{(}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{)} \AgdaSymbol{:} \AgdaPrimitiveType{Set} \AgdaKeyword{where}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{\_∷\_} \AgdaSymbol{:} \AgdaBound{A} \AgdaSymbol{→} \AgdaDatatype{∞} \AgdaSymbol{(}\AgdaDatatype{Stream} \AgdaBound{A}\AgdaSymbol{)} \AgdaSymbol{→} \AgdaDatatype{Stream} \AgdaBound{A}\<%
\end{code}

The delay operator $\infty$ denotes a coinductive argument. Given $a:A$, the expression with a delay function $\sharp~a$ is an element of type $\infty~A$. $\flat~x$ will force computation in $x : \infty~A$.


\item \textit{Ring solver}. Compared to Coq, Agda has no tactics including automated proving although it has a ring solver which plays a similar role to the tactic \textit{ring}. It is easy to use for people who are familiar with constructive \maths.
\end{itemize} 


\subsection{Agda conventions}\label{agdaconventions}

The syntax of Agda has some similarities to Haskell or \mltt, but there are some important differences which may make confusions,

\begin{itemize}

\item The meaning of $\AgdaSymbol{=}$ is swapped with the one of $\AgdaDatatype{≡}$. The symbol "$\AgdaSymbol{=}$" is reserved for function definition as the convention in programming languages. The congruence symbol "$\AgdaDatatype{≡}$'' is used for identity type. This is inconsistent with our conventional choice of symbols in articles.

\item $\AgdaSymbol{:}$ is used for typing judgement, for example $\AgdaFunction{a} \AgdaSymbol{:} \AgdaDatatype{A}$, while double colons $\AgdaSymbol{::}$ is the \emph{cons} constructor for list.
It is different from the usual notational conventions in Haskell.

\item The universe of small types is $\Set_{0}$ or $\Set$ instead of $\Type$, even though it is not a set in set-theoretical sense.
%We will follow the \textbf{typical ambiguity} in this thesis which says that we write $\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}$ for $\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set} \AgdaBound{a}$ and $\AgdaPrimitiveType{Set} \AgdaSymbol{:} \AgdaPrimitiveType{Set}$ which stands for $\AgdaPrimitiveType{Set}\AgdaBound{i} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaBound{(i+1)}$.

\item The universe of propositions $\Prop$ ($\Prop \subset \Set$) is not available. Propositions are also in the universe $\Set$. If necessary, we will postulate the proof-irrelevance property for a given proposition $P : \Set$.

\item Agda has a more liberal way to define $\Pi$-types. $\Pi$-types are written in a generalized
arrow notation $(x : A) → B$ for $\Pi x:A.B$. Together with implicit arguments, it is valid to write a type signature as $\forall\{A : \Set \}(x : A) \to \{y : A\} \to x \equiv y$.


\item $\Sigma$-types are defined in Agda standard library. There is also a generalised $\Sigma$-types called \emph{dependent record type} which can be defined by keyword \textbf{record}.


\item In Agda, we use Paulin-Mohring style identity type,

\begin{code}
\\
\>\AgdaKeyword{data} \AgdaDatatype{\_≡\_} \AgdaSymbol{\{}\AgdaBound{A} \AgdaSymbol{:} \AgdaPrimitiveType{Set}\AgdaSymbol{\}} \AgdaSymbol{(}\AgdaBound{x} \AgdaSymbol{:} \AgdaBound{A}\AgdaSymbol{)} \AgdaSymbol{:} \AgdaBound{A} \AgdaSymbol{→} \AgdaPrimitiveType{Set} \AgdaKeyword{where}\<%
\\
\>[0]\AgdaIndent{2}{}\<[2]%
\>[2]\AgdaInductiveConstructor{refl} \AgdaSymbol{:} \AgdaBound{x} \AgdaDatatype{≡} \AgdaBound{x}\<%
\\
\end{code}
It is parametrised by the left side of the identity which is equivalent to the original version.
\end{itemize}



\section{Extensional concepts}
\label{extensionality}



In \itt, extensional (propositional) equality is not captured by the identity type which is intensional.

However, the identity type in intensional type theory is not powerful enough for formalisation of mathematics and program development. Notably, it does not identify pointwise equal functions (functional extensionality) and provides no means of redefining equality on a type as a given relation, i.e. quotient types. We call such capabilities extensional concepts.



Objects are extensionally equal, if they have same the \emph{observable} behaviours, in other words they  can be substituted by the other in any contexts without changing the meaning of a program. For example point-wise equal functions, different proofs of the same proposition etc. Extensional (propositional) equality is not captured by the identity type which is intensional.
Thus in the traditional formulation of \itt, extensionality and some other related features of propositional equality like quotient types are not available. These \emph{extensional concepts} has been comprehensively studied by Martin Hofmann \cite{hof:phd} a list of them are given as follows:


\begin{itemize}

\item \textbf{Functional extensionality} 


\infrule[fun-ext]{\Gamma \vdash A \andalso \Gamma , x : A \vdash B \andalso \Gamma \vdash f, g : \Pi (x : A) ~B \\ \Gamma, a : A \vdash p: f(a) = g(a)}{\Gamma \vdash \text{ext}(p): f = g}

 If two (dependent) functions point-wise propositionally equal, they are (extensional) propositionally equal. This is called
functional extensionality which is not inhabited in traditional formulation \itt \cite{alti:lics99}.
For example, two functions of type $\N \to \N$, $\lambda n \to n$ and $\lambda n \to n + 0$ are point-wise propositional equal, but the intensional propositional equality of them is not inhabited due to the fact that $n + 0$ does not reduce to $n$ (assume $\_+\_$ is defined as the one in \autoref{features}).

%given two types $A$ and $B$, and two functions $f,\,g\,\colon A \to B$,

%\[Ext = \forall\, x\colon A, f x = g x \to f = g\]

It is inhabited in \ett since it is provable from equality reflection rule \ref{reflection}:
 
\begin{proof}\label{prf:ertofe}
Suppose $\Gamma , a : A \vdash p : f \,a = g \,a$, with reflection rule we have $\Gamma ,a : A \vdash f \,a \equiv g \,a$.
Then using $\xi$-rule, we know that $\Gamma \vdash \lambda a . f \,a \equiv \lambda a . g \,a$.
From the $\eta$-rule of $\Pi$-types and the transitivity of $\equiv$, we know that $\Gamma \vdash f \equiv g$. Finally we can conclude that $\Gamma \vdash \text{refl}(f) : f = g$.
\end{proof}

In \itt, if we postulate it, the type theory is not \emph{adequate}, which means canonicity is lost:

\begin{proof}[Non-canonical construction]\label{noncanonical}
Suppose we define $id \defeq \lambda x . x$ and $id' \defeq \lambda x . x + 0$, recursively it is provable that $p': \forall x , id~ x = id'~x$, from functional extensionality we obtain $\text{ext} ~p' : id = id'$. We can use substitution to construct non-canonical natural numbers, for instance $\text{subst}~ (\lambda f. \N) ~(\text{ext} ~p') ~0$. This is non-canonical because the equality is non-canonical (not refl) so that the expression cannot be normalised.
With this term, we can construct irreducible terms of any type $A$ by a
mapping $f : \N \to A$.
\end{proof}

%This will destroy some good features of \itt. The non-canonical terms makes definitional equality undecidable and so is type checking. The termination of type checker is not assured and programs may be non-terminating.



\item \textbf{Uniqueness of Identity Proof (UIP)}\label{UIPdetail}

%\begin{definition}\label{UIP}
%\textbf{Uniqueness of identity proofs} Any two terms of a given identity type $p,q : x =_{A} y$ are thems%elves propositionally equal $p =_{x = y} q$.
%\end{definition}


\infrule[UIP]{\Gamma \vdash A \andalso \Gamma \vdash x , y : A \andalso \Gamma \vdash p, q : x = y}{\Gamma \vdash \text{uip}(p,q): p = q}



UIP is not a consequence of the fundamental eliminator for identity type $\J$ as shown in Hofmann and Streicher's groupoid interpretation of Type Theory \cite{MR1686862}. It holds if we add another eliminator $\K$ introduced by Streicher in \cite{streicherinvestigations} as follows:

%\begin{axiom}[$\K$]
%For all $x:A$ and $p: x =_A x$ we have $p=\text{refl}_{x}$.
%\end{axiom}

\infrule[$\K$]{\Gamma \vdash a : A \andalso \Gamma, x : a = a \vdash C(x) \\ \Gamma \vdash t : C(r(a)) \andalso \Gamma \vdash p : a = a }{\Gamma \vdash \K (t,p) : C(p)}

computation rule:
$$\K (t , r(a)) \equiv t$$

In programming languages such as Agda and Epigram, UIP and $\K$ are provable using dependent pattern matching. We can add an Agda flag ``--without-K'' to deny pattern matching on $a = a$ if we do not accept UIP in general. 
Although UIP for arbitrary types is not derivable, types equipped with decidable equality have the property UIP as shown by Michael Hedberg \cite{hed:98}.
A construction of the proof can be found in \cite{NisseHedberg}.

In \hott, an \emph{h-set} is a type who has UIP e.g. $\N$ (See \autoref{hott}).
%As we mentioned before, we would like to interpret types as groupoids or higher groupoids instead of sets, UIP does not hold in general. A type $A$ is a \textbf{set} (or h-set in \hott) if UIP holds for it.


%Another characterisation of a set in Type Theory is given by Hedberg's Theorem.
%\begin{theorem}[Hedberg]
%If $A$ has decidable equality, then $A$ is a set.
%\end{theorem}


\item \textbf{Proof irrelevance} 

%\red{Proof irrelevance refers to the principle that the choice of proofs of the same proposition is  irrelevant in arbitrary contexts}. 

In traditional \itt, there is no universe of propositions $\Prop$ which has proof irrelevance:

\infrule[proof-irr]{\Gamma \vdash P : \Prop \andalso \Gamma \vdash p,q : P}{\Gamma \vdash p \equiv q : P}

We usually use $\Set$ instead which does not automatically gives us a proof that $(p, q : P) \to p = q$.


An example of \itt extended with $\Prop$ is the metatheory of Altenkirch's setoid model (see \autoref{setoidmodel}).


In \hott, $\Prop$ is usually treated as the universe of h-propositions which are types of h-level 1 (see \autoref{hottinterpretation}). One can think h-propositions as the sets which has proof-irrelevance property, hence 

$$\HProp = \Sigma (A : \Set) ~((a, b : A) \to a = b)$$.

 It is different to a universe of propositions because not every set behaves like a proposition must be in $\Prop$, while it is the case for $\HProp$. 


If we have proof irrelevance, we can simply define identity type for sets as $x = y : \Prop$ and UIP is provable.


\item \textbf{Propositional extensionality} 


\begin{equation}
\forall P, Q : \Prop \to (P \iff Q) \to (P = Q)
\end{equation}

Propositional equality between two propositions is given by logically equivalence. Similarly it only make senses if there is $\Prop$.

\item \textbf{Quotient types} 

A quotient type is a type formed by redefining equality on a underlying type with a given equivalence relation on it. It is the main topic of this thesis and is discussed in detail in \autoref{qt}.

\item \textbf{Univalence}

Univalence is an extensional principle from homotopy theory which is an axiom in \hott. 
It states:

Given any two types $A,B$, the canonical mapping $(A = B) \to (A \simeq B)$ is an equivalence.

Equivalence can be thought of a refinement of isomorphism in higher categories. The notions of \hott is discussed in \autoref{hott}.
\end{itemize}

\subsection{Conservativity of TT$_E$ over TT$_I$ with extensional concepts}

In \ett where we accept equality reflection and UIP, many extensional concepts are derivable, for example functional extensionality is derivable from equality reflection with $\eta$-rule for $\Pi$-types, see \autoref{prf:ertofe}. Compared to \itt it seems to be more appealing to mathematicians who are more familiar with Set Theory. However the type checking is undecidable which has been formally proved by Hofmann in \cite{hof:phd}. This makes \itt more favourable, so adding extensional principles into \itt  
is one of the most important topic in Type Theory. It is preferable if the decidability of type-checking and canonicity are not sacrificed. 
It is also valid and justifiable to extend TT$_I$ with them. 

The following theorem proved by Hofmann in \cite{hof:95:con} states that TT$_E$ is conservative over TT$_I$ with functional extensionality and uniqueness of identity added. $\|\_\|$ is an interpretation of TT$_I$ into TT$_E$ and the judgements are differentiated by the subscript of $\vdash$.

\begin{theorem}
If $\Gamma \vdash_I A : \Set$ and $\| \Gamma \| \vdash_E a : \| A \|$ for some $a$ then there exists $a'$ such that $\Gamma \vdash_I a' : A$
\end{theorem}


Briefly speaking it is proved by using a model $\mathbf{Q}$ of TT$_I$, for example categories with families (see \autoref{cwf:def}) in the sense of Dybjer which is also a model of TT$_E$ due to the mapping $\|\_\|$ discussed above. The interpretation of the term $a$ in this model gives a term of type $A$ by fullness in TT$_I$, hence $a'$. The detailed proof can be found in \cite{hof:95:con}. In the model $\mathbf{Q}$, types and contexts are propositionally equal if they are isomorphic, which becomes definitional equal in TT$_E$. The proof is also applied to quotient types which has been shown in \cite{hof:phd}.
However, the proof is non-constructive so that it does not provide an algorithm to compute the term $a'$.








% intuitionism
% There is another question, whether mathematics is a collection of patterns and laws which is observed, or it is a system created and built by people to explain the patterns and laws in the world. I think people prefer the second answer usually accept the type theory more easily, although most people (probably 99.9 percent) prefer the first one. When we learn what is natural numbers, we learn it as "numbers like 1, 2, 3 ,4 and perhaps 0", the commutative law, associate law are axioms because there is no way to prove it if we introduce it in this manner. We are convinced by some examples like "2 + 3 = 3 + 2" and we find it works for most of the cases then we accept it by observations. It is some methods physicians used a lot -- to conclude some laws from a number of facts. It is a proper method for physicians because what they research on is world can only be observed. However for mathematics, even though it is applied to the real world, it is a system completely created by people. People used their fingers to count, wrote symbols for results, even though it was very shallow it is obviously a aritificial system. People extend 


% Type theory is strongly connected with computation theory.
% Set

% Type theory has fewer axioms, simpler model than set theory which has mutual foudations: logic and axioms.




%although the absence of \emph{principle of excluded middle} in intuitionistic logic makes some mathematicians hard to accept. There is a very good talk given by Andrej Bauer in IAS called "Five Stages of Accepting Constructive Mathematics'' online \footnote{available on Youtube}.



%is worth more studying. It is more close to program construction and from a computer scientist's point of view, it is very natural to accept intuitionistic logic. 


\section{An \itt with $\Prop$}\label{ittprop}

Altenkirch has introduced an extension of \itt by a universe of proof-irrelevant propositions and $\eta$-rules for $\Pi$-types and $\Sigma$-types \cite{alti:lics99}. It is used as a metatheory for his setoid model (see \autoref{models}).

The proof-irrelevant universe of proposition $\Prop$ is a subuniverse of  $\Set$ i.e.\ $p : \Prop$ implies $p : \Set$. It only contains sets with at most one inhabitant:

\infrule[proof-irr]{\Gamma \vdash P : \Prop \andalso \Gamma \vdash p,q : P}{\Gamma \vdash p \equiv q : P}

We also introduce $\top, \bot : \Prop$ as basic propositions which are similar to the unit types and empty types (see \ref{typerule}), namely we have $tt : \top$, and $\text{abort}(e) : A$ for any type $A$ and any $e : \bot$.

 Notice that it is not a definition of types, which means
that we cannot conclude a type is of type \textbf{Prop} if we have a
proof that all inhabitants of it are definitionally equal.

The propositional universe is closed under $\Pi$-types and $\Sigma$-types:

\infrule[$\Pi$-Prop]{\Gamma \vdash A : \Set \andalso \Gamma, x : A \vdash P : \Prop}
{\Gamma \vdash \Pi~ (x : A) ~ P : \Prop}


\infrule[$\Sigma$-Prop]{\Gamma \vdash P : \Prop \andalso \Gamma,x : P \vdash Q : \Prop}
{\Gamma \vdash \Sigma ~(x : P) ~ Q : \Prop}

We may also use shorthand notation for $\Pi$-types, for example $(x:A) \to P$ or $\forall (x : A) \to P$, $P \wedge Q$ if $Q$ does not depend on $P$.


The metatheory is then proved to be:

\begin{itemize}
\item Decidable. The definitional equality is decidable, hence type checking is decidable.

\item Consistent. Not all types inhabited and not all well typed definitional equality holds. 

\item Adequate. All terms of type $\N$ are reducible to numerals.
\end{itemize}

The proof can be found in \cite{alti:lics99}.


\section{Homotopy Type Theory}\label{hott}

\hott (HoTT) refers to a new interpretation of intensional \mltt
into \emph{abstract} homotopy theory.
It accepts Vladimir Voevodsky's \textbf{univalence axiom} and a new schema to define types called \emph{higher inductive types}, which make many extensional concepts derivable including quotient types.


\subsection{Homotopic interpretation}\label{hottinterpretation}

Types are usually interpreted as sets in \mltt, but the identity type of types enforces a more sophisticated structure on types compared to the one on sets due to the missing Axiom $\mathsf{K}$ for which asserts that all inhabitants are equal to the only constructor $\mathsf{refl}$. 

Inspired by the groupoid model of (intensional) Martin-Löf type theory due to Hofmann and Streicher, Awodey, Warren \cite{awodey-warren} and Voevodsky \cite{VV} develops \hott which is a homotopic interpretation of \mltt.

In \hott, types are regarded as spaces (or higher groupoids) instead of sets, terms are "points" of types. A function $f : A \to B$ is a continuous map between spaces $A$ and $B$.

\begin{itemize}
\item Types are interpreted as spaces. $a : A$ can be stated as $a$ is
  a point of space $A$.
\item Terms are continuous functions, for example, $f : A \rightarrow B$ is a
  continuous function between spaces and it is equivalent to say that $a$ is
  a point of the space or $a : 1 \rightarrow A$ is a continuous function.
\item Identity types are path spaces.
\item Identity types of identity types are homotopies (if a path is considered as a continuous function $p : [0,1] \rightarrow X$).
\item There are also 3-homotopies and 4-homotopies and higher
  levels which forms an infinite structure called \og in higher category theory.
\end{itemize}

\begin{remark}
It has to be emphasised that the notions like spaces are purely homotopical, in other words, there are no topological notions like open sets in \hott. 
\end{remark}

%Therefore it is more appropriate to interpret types as \og instead of spaces. 

We can also interpret types as \textbf{\og}. 
An \ogs (or weak $\infty$-groupoids) is an $\omega$-category where all $k$-morphisms for all $k \in \N$ are equivalences. $k$-morphisms between $(k - 1)$-morphisms, for all $k \in \N$ . n equivalence is a morphism which is invertible up to all higher equivalences. 

The notion of \ogs is a generalisation of groupoid which has infinite levels of "isomorphisms" corresponding to the infinite tower of iterated identity types, i.e.\ the identity type of identity type, the identity type of identity type of identity type etc.

The notion of equivalence can be seen as a refinement of isomorphism without UIP \cite{txa:csl}. 
In the higher-categorical setting, equivalence can be thought of as arising from isomorphisms by systematically replacing equalities by higher cells.
For example, an equivalence 
between two objects $A$ and $B$ in a 2-category is a morphism $f : A \rightarrow B$ which has a
corresponding inverse morphism $ g : B \rightarrow A$, but instead of the
equalities $f ∘ g = 1_B$ and $g ∘ f = 1_A$ we have 2-cell isomorphisms $f ∘ g ≅ 1_B$ and $g ∘ f ≅ 1_A$. In an $\omega$-category, these later isomorphisms are equivalences again.
These equivalences are \emph{weak} in the sense that they only hold up to higher equivalences. 
As all equivalences here are weak equivalences, from now on we say just equivalence.
In fact the \og used to model the identity types are also weak, so we should call them \textbf{\wog}.



To distinguish these structured objects interpretation from usual set-like types, we also call them \textbf{homotopy types}. Although we interpret all types as \og, most types behave internally like $k$-groupoid for some $k \in \N$, which is called \textbf{truncation}. An $n$-truncated \ogs is an $n$-groupoid.

In \hott the notion of \textbf{homotopy $n$-types} are analogous to $n$-groupoids in higher category theory. A set can be seen as a discrete space which is $0$-groupoid. Thus a set is called homotopy $0$-type or \textbf{h-set} which is of \textbf{homotopy level} (or h-level) $2$. It is a fact that the identity type of an $(n+1)$-type is an $n$-type, for example, the identity type of a groupoid is a set. Following this relation, a $(\minusS 1)$-type is a proposition (\textbf{mere proposition} or \textbf{h-proposition} in \hott) and $(\minusS 2)$-type is a unit type or contractible type.

\subsection{Univalence Axiom}

Voevodsky recognised that the homotopic interpretation is \emph{univalent} which means isomorphic types are equal, which does not usually hold in \itt. 
It is one of the fundamental axioms of \hott and is central to the Voevodsky's proposal of Univalent Foundation Project \cite{vv_uf}. 

For any two types $A, B$, there is a canonical mapping $$f : X = Y \to X \simeq Y$$ derived from induction on identity types. The univalence axiom just claims that this mapping is an equivalence. 


It can be viewed as a strong extensionality which does imply functional extensionality (a Coq proof of this can be found in \cite{uafe}). 
Since isomorphic types are considered the same, all constructions and proofs are automatically transported between them, and it actually makes reasoning abstract.


\subsection{Higher inductive types}\label{HITs}

In \itt, types are treated as sets and we use \emph{inductive types} to define sets which have only "points". However, in \hott, due to the enriched structures of types, inductive types are not expressive enough.

A more general schema to define types including higher paths is required which is higher inductive types (HITs). Higher inductive types allow constructors not only for points of the type being defined, but also for elements of its iterated identity types.
One commonly used example is the circle $\Sn^1$ (1-sphere) which can be \emph{inductively} defined as:

\begin{itemize}
\item A point $\base:\Sn^1$, and
\item A path $\lloop : {\id[\Sn^1]\base\base}$.
\end{itemize}

It is also essential to provide the elimination rule for the paths as well. Categorically speaking, it means that the functions have to be functorial. For example, to define a function $f :\Sn^1 \rightarrow B$, assume $f(base)=b$, we have to map $\lloop$ to an identity path $l : b = b$, i.e.\ $ap_{f}(\lloop)=l$.


In \hott, many extensional concepts are derivable. As we have seen, functional and propositional extensionality and are both implied by univalence, UIP for h-sets, proof irrelevance for h-propositions are also available.

Quotient types, or more precisely quotient sets because of the different interpretation of types, are also available. We will discuss it in detail in \autoref{qthott}.

For further explanation of \hott, a well-written text book elaborated by a group of mathematicians and computer scientists is available online \cite{hott}. 


\subsection{Towards a computational interpretation of HoTT}

One of the most important challenges in \hott is to build a constructive model which would give us a computational interpretation of univalence, so that the good computational properties of Type Theory are preserved \cite{bezem2013model}. 

There are different models based on Kan simplicial sets, cubical sets and a syntactic approach to define \wog in \itt on which the author has done some work (See \autoref{wog}).


To interpret types as weak $\omega$-groupoids, one main problems is
the complexity of the definition of weak $\omega$-groupoid. The
coherence conditions are very difficult to specify. Nevertheless there are some attempt of encoding \wog in Type Theory including a syntactic implementation of \wog by the author, Altenkirch and Ryp\'{a}\v{c}ek
in Agda (see \autoref{wog}).

It is much simpler to interpret types as \emph{Kan simplicial sets}.
Voevodsky's univalent model \cite{klv:ssetmodel} is based on Kan simplicial sets. 
There is a concise introduction written by Streicher \cite{DBLP:dblp_journals/japll/Streicher14}. 
However the simplicial set model is not constructive as Coquand showed
that it requires classical logic in an essential way \cite{TC:sset}.
To avoid the use of classical logic, types can be interpreted as \emph{semi-simplicial sets}. We have not successfully implemented the notion of semi-simplicial sets in an \itt like Agda. Some relevant discussion of it can be found online \cite{ssSet}.

Recently, Bezem, Coquand and Huber \cite{bezem2013model} proposed another model of dependent type theory 
in \emph{cubical sets}. It is expressed in a constructive metalogic which makes it a more plausible model for obtaining a computational interpretation of univalence.

%Similarly, a cubical set is a presheaf on cube category, denoted as $S : \Box^{op} \rightarrow \Set$ . Different from simplicial set model, it is expressed in a constructive metalogic which makes it a more plausible model for obtaining a computational interpretation of univalence.

%\begin{remark}[Simplicial set]
%A simplicial set $X$ is a functor from $\Delta^{op}$ to $\Set$ where
%$\Delta$ is the simplex category.

%$\Delta^{op}$ is a category whose objects are non-empty totally ordered
%finite sets. The morphisms are order-preserving functions. 
%Face maps and degeneracy maps are the most important morphisms in this
%category.

%A simplex is a generalisation of a triangle to arbitrary
%dimensions. A $3$-dimensional simplex is tetrahedron and a $(k+1)$-simplex can
%be obtained by adding one point to $k$-simplex which does not lie in the
%dimension where the $k$-simplex is.

%A simplicial complex is a collection of simplices. Topologically speaking, it
%is constructed by gluing n-dimensional simplexes together. 
%\todo{show an example graph}

%A simplicial set, therefore, can be illustrated by the same graph where
%the set of points is given by $X_0$, the set of lines is $X_1$ and so
%on.
%\end{remark}

%To avoid the use of classical logic, types can be interpreted as \emph{semi-simplicial sets} which are similar to simplicial sets, but there are only face maps
%but no degeneracy maps. We can denote a semi-simplicial set as a
%functor $X : \Delta_{inj} \rightarrow \Set$. The morphisms in $\Delta_{inj}$ are not only order preserving but also injective.
%An “iterated dependency” approach is believed to solve the coherence
%issues. However we have not successfully implemented the notion of semi-simplicial sets in an \itt like Agda. Some relevant discussion of it can be found online \cite{ssSet}.
%Klaus and me were trying to implement semi-simplical set in Agda. 

\section{Summary}


The theory of types was originally invented to resolve an inconsistency in set theory in 1900s. After that, mathematicians developed it by adding more properties, for example functions as primitive types, Curry-Howard isomorphism. Type theory is closely related to type systems in programming languages, and some type theories like the simply-typed lambda calculus, Per Martin L\"{o}f's intuitionistic type theory and the calculus of constructions, are themselves programming languages. 

\mltt is one of the most modern type theories which is closely related to constructive \maths and computer science. It is a formal system given by a sequence of rules written as derivations of judgements. Because of Curry-Howard isomorphism and dependent types, we can implement intuitionistic logic in Type Theory. It means that we can do constructive reasoning by program constructions. From a mathematician's point of view, it provides computer-aided formal reasoning in languages like Agda and Epigram. From a a programmer's point of view, it provides program verification in itself and a more expressive way to write specifications for programs.

The intensional version of \mltt has decidable type checking which is a popular choice in programming languages. Agda is one of these languages and it has many good features supporting mathematical constructions and reasoning. It is used a lot in academia by theoretical computer scientists and mathematicians for example the \hott community. 

Despite the good properties of \itt, it lacks many extensional concepts like functional extensionality and quotient types. Much research has been done to add them into Type Theory without losing the computational property of Type Theory. This thesis is one attempt in this direction.

Finally we discussed \hott where many extensional concepts including quotient types (in the sense \autoref{iqs}) are available. 
We briefly compared different models of \hott where types are interpreted as different forms of \wog. However only constructive models can possibly provide a computational interpretation of univalence.
A potential solution is the cubical set model.







